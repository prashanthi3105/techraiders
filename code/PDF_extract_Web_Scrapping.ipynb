{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz spacy requests beautifulsoup4\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCXmXMHNxP0U",
        "outputId": "ab43eeea-3096-429e-ea2e-a4d2b26cdf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.8)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (6.0.1)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (4.0.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.8.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (1.5.3)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.2.1)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.0)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (7.0.0)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.2)\n",
            "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.13.1)\n",
            "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.4)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.4)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.26)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cctNApDiTdx"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF library for PDF parsing\n",
        "import spacy  # For natural language processing tasks\n",
        "from bs4 import BeautifulSoup  # For web scraping\n",
        "import requests  # For making HTTP requests\n",
        "from transformers import BertTokenizer, BertForSequenceClassification  # For BERT-based model\n",
        "from flask import Flask, request, jsonify  # For creating a web service\n",
        "import unittest  # For unit testing\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def process_text(text):\n",
        "    # Process the text using spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract entities\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    # Extract relationships (TODO: Define your logic for relationships)\n",
        "\n",
        "    # Extract sentiment (TODO: Define your logic for sentiment analysis)\n",
        "\n",
        "    return entities\n",
        "\n",
        "def pdf_parser(url):\n",
        "    # Fetch the PDF content from the URL\n",
        "    response = requests.get(url)\n",
        "    with open(\"temp.pdf\", \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    text = \"\"\n",
        "    # Open the PDF file\n",
        "    with fitz.open(\"temp.pdf\") as pdf:\n",
        "        for page_num in range(len(pdf)):\n",
        "            page = pdf.load_page(page_num)\n",
        "            text += f\"\\nPage Number: {page_num + 1}\\n\"\n",
        "            text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    # Open the PDF file\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        # Iterate through each page\n",
        "        for page_num in range(len(pdf)):\n",
        "            page = pdf.load_page(page_num)\n",
        "            # Extract text from the page\n",
        "            text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "def retrieve_information(text):\n",
        "    # Load the pre-trained BERT model for question answering\n",
        "    qa_model = pipeline(\"question-answering\")\n",
        "    # Define the question/query to ask the model\n",
        "    question = \"What is the net zero target?\"\n",
        "    # Use the model to retrieve the answer from the text\n",
        "    answer = qa_model({\"question\": question, \"context\": text})\n",
        "    return answer[\"answer\"]\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/extract-information\", methods=[\"POST\"])\n",
        "def extract_information():\n",
        "    data = request.json\n",
        "    pdf_text = data[\"pdf_text\"]\n",
        "    extracted_information = retrieve_information(pdf_text)\n",
        "    return jsonify({\"extracted_information\": extracted_information})\n",
        "\n",
        "def scrape_website(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    # Use BeautifulSoup to extract relevant information from the webpage\n",
        "    return soup\n",
        "\n",
        "def compare_indices(benchmarking_data, target_company_data, competitors_data):\n",
        "    # Initialize a dictionary to store the comparison results\n",
        "    comparison_results = {}\n",
        "\n",
        "    # Compare benchmarking indices for the target company\n",
        "    target_comparison_result = {}\n",
        "    for index, value in benchmarking_data.items():\n",
        "        if index in target_company_data:\n",
        "            # Compare the benchmarking index value with the extracted information for the target company\n",
        "            if value == target_company_data[index]:\n",
        "                target_comparison_result[index] = \"Match\"\n",
        "            else:\n",
        "                target_comparison_result[index] = \"Mismatch\"\n",
        "\n",
        "    # Store the comparison results for the target company\n",
        "    comparison_results[\"Target Company\"] = target_comparison_result\n",
        "\n",
        "    # Compare benchmarking indices for each competitor\n",
        "    for competitor, competitor_data in competitors_data.items():\n",
        "        competitor_comparison_result = {}\n",
        "        for index, value in benchmarking_data.items():\n",
        "            if index in competitor_data:\n",
        "                # Compare the benchmarking index value with the extracted information for the competitor\n",
        "                if value == competitor_data[index]:\n",
        "                    competitor_comparison_result[index] = \"Match\"\n",
        "                else:\n",
        "                    competitor_comparison_result[index] = \"Mismatch\"\n",
        "\n",
        "        # Store the comparison results for the competitor\n",
        "        comparison_results[competitor] = competitor_comparison_result\n",
        "\n",
        "    return comparison_results\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    # Open the PDF file\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        # Iterate through each page\n",
        "        for page_num in range(len(pdf)):\n",
        "            page = pdf.load_page(page_num)\n",
        "            # Extract text from the page\n",
        "            text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "def fetch_benchmarking_indices():\n",
        "    benchmarking_indices = {}\n",
        "\n",
        "    # GRI Website\n",
        "    gri_url = \"https://www.globalreporting.org/\"\n",
        "    gri_indices = fetch_indices_from_website(gri_url)\n",
        "    benchmarking_indices[\"GRI\"] = gri_indices\n",
        "\n",
        "    # SASB Website\n",
        "    sasb_url = \"https://sasb.ifrs.org/\"\n",
        "    sasb_indices = fetch_indices_from_website(sasb_url)\n",
        "    benchmarking_indices[\"SASB\"] = sasb_indices\n",
        "\n",
        "    # TCFD Website\n",
        "    tcfd_url = \"https://www.fsb-tcfd.org/\"\n",
        "    tcfd_indices = fetch_indices_from_website(tcfd_url)\n",
        "    benchmarking_indices[\"TCFD\"] = tcfd_indices\n",
        "\n",
        "    # CDP Website\n",
        "    cdp_url = \"https://www.cdp.net/en\"\n",
        "    cdp_indices = fetch_indices_from_website(cdp_url)\n",
        "    benchmarking_indices[\"CDP\"] = cdp_indices\n",
        "\n",
        "    return benchmarking_indices\n",
        "\n",
        "def fetch_indices_from_website(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Logic to extract benchmarking indices from the website\n",
        "        indices = []\n",
        "        # Example logic for extracting indices from SASB website\n",
        "        if \"sasb\" in url:\n",
        "            index_elements = soup.select(\".indices-list li\")\n",
        "            for element in index_elements:\n",
        "                indices.append(element.text.strip())\n",
        "\n",
        "        # Example logic for extracting indices from TCFD website\n",
        "        elif \"fsb-tcfd\" in url:\n",
        "            index_elements = soup.select(\".tcfd-standards li\")\n",
        "            for element in index_elements:\n",
        "                indices.append(element.text.strip())\n",
        "\n",
        "        # Example logic for extracting indices from CDP website\n",
        "        elif \"cdp\" in url:\n",
        "            index_elements = soup.select(\".cdp-indices li\")\n",
        "            for element in index_elements:\n",
        "                indices.append(element.text.strip())\n",
        "\n",
        "        # Add logic for other websites as needed\n",
        "\n",
        "        return indices\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching benchmarking indices from {url}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Main function to orchestrate the process of retrieving and organizing benchmarking data\n",
        "def main():\n",
        "    # Define the company name for which you want to retrieve benchmarking data\n",
        "    company_name = \"ametek\"\n",
        "\n",
        "    # Retrieve benchmarking data from multiple sources\n",
        "    benchmarking_data = retrieve_benchmarking_data(company_name)\n",
        "\n",
        "    # Print the retrieved benchmarking data\n",
        "    print(\"Retrieved Benchmarking Data:\")\n",
        "    for source, data in benchmarking_data.items():\n",
        "        print(f\"Source: {source}\")\n",
        "        print(data)\n",
        "        print()\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}